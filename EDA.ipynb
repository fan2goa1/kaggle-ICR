{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder,normalize\n",
    "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import xgboost\n",
    "import inspect\n",
    "from collections import defaultdict\n",
    "from tabpfn import TabPFNClassifier\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./icr-identify-age-related-conditions/train.csv')\n",
    "test = pd.read_csv('./icr-identify-age-related-conditions/test.csv')\n",
    "sample = pd.read_csv('./icr-identify-age-related-conditions/sample_submission.csv')\n",
    "greeks = pd.read_csv('./icr-identify-age-related-conditions/greeks.csv')\n",
    "\n",
    "first_category = train.EJ.unique()[0]\n",
    "train.EJ = train.EJ.eq(first_category).astype('int')\n",
    "test.EJ = test.EJ.eq(first_category).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_denominators = {\n",
    "    'AB': 0.004273,\n",
    "    'AF': 0.00242,\n",
    "    'AH': 0.008709,\n",
    "    'AM': 0.003097,\n",
    "    'AR': 0.005244,\n",
    "    'AX': 0.008859,\n",
    "    'AY': 0.000609,\n",
    "    'AZ': 0.006302,\n",
    "    'BC': 0.007028,\n",
    "    'BD ': 0.00799,\n",
    "    'BN': 0.3531,\n",
    "    'BP': 0.004239,\n",
    "    'BQ': 0.002605,\n",
    "    'BR': 0.006049,\n",
    "    'BZ': 0.004267,\n",
    "    'CB': 0.009191,\n",
    "    'CC': 6.12e-06,\n",
    "    'CD ': 0.007928,\n",
    "    'CF': 0.003041,\n",
    "    'CH': 0.000398,\n",
    "    'CL': 0.006365,\n",
    "    'CR': 7.5e-05,\n",
    "    'CS': 0.003487,\n",
    "    'CU': 0.005517,\n",
    "    'CW ': 9.2e-05,\n",
    "    'DA': 0.00388,\n",
    "    'DE': 0.004435,\n",
    "    'DF': 0.000351,\n",
    "    'DH': 0.002733,\n",
    "    'DI': 0.003765,\n",
    "    'DL': 0.00212,\n",
    "    'DN': 0.003412,\n",
    "    'DU': 0.0013794,\n",
    "    'DV': 0.00259,\n",
    "    'DY': 0.004492,\n",
    "    'EB': 0.007068,\n",
    "    'EE': 0.004031,\n",
    "    'EG': 0.006025,\n",
    "    'EH': 0.006084,\n",
    "    'EL': 0.000429,\n",
    "    'EP': 0.009269,\n",
    "    'EU': 0.005064,\n",
    "    'FC': 0.005712,\n",
    "    'FD ': 0.005937,\n",
    "    'FE': 0.007486,\n",
    "    'FI': 0.005513,\n",
    "    'FR': 0.00058,\n",
    "    'FS': 0.006773,\n",
    "    'GB': 0.009302,\n",
    "    'GE': 0.004417,\n",
    "    'GF': 0.004374,\n",
    "    'GH': 0.003721,\n",
    "    'GI': 0.002572\n",
    "}\n",
    "for k, v in int_denominators.items():\n",
    "    train[k] = np.round(train[k] / v, 1)\n",
    "    test[k] = np.round(test[k] / v, 1)\n",
    "\n",
    "# ff = ['Id', 'AH', 'BN', 'BQ', 'CB', 'CC', 'CR', 'CU', 'DA', 'DE', 'DN', 'EE', 'EP', 'FI', 'GF', 'Class']\n",
    "# gg = ['Id', 'AH', 'BN', 'BQ', 'CB', 'CC', 'CR', 'CU', 'DA', 'DE', 'DN', 'EE', 'EP', 'FI', 'GF']\n",
    "# train = train[ff]\n",
    "# test = test[gg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "\n",
    "columns_to_select = [col for col in train.columns if col not in ['Class', 'Id']]\n",
    "\n",
    "train_data = train[columns_to_select].copy()\n",
    "test_data = test[columns_to_select].copy()\n",
    "\n",
    "# 填充缺失值\n",
    "train_data = pd.DataFrame(Imp.fit_transform(train_data), columns=columns_to_select)\n",
    "test_data = pd.DataFrame(Imp.transform(test_data), columns=columns_to_select)\n",
    "\n",
    "# 重新组合数据和原始列\n",
    "train_filled = pd.concat([train['Id'], train_data, train['Class']], axis=1)\n",
    "test_filled = pd.concat([test['Id'], test_data], axis=1)\n",
    "\n",
    "train = train_filled.copy()\n",
    "test = test_filled.copy()\n",
    "# print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "k = 5\n",
    "BNpd = train['BN']\n",
    "\n",
    "BNpd = pd.concat([train['BN'], test['BN']], axis=0, ignore_index=True)\n",
    "data = BNpd.values.reshape(-1, 1)\n",
    "kmodel = KMeans(n_clusters=k)           # k为聚成几类\n",
    "kmodel.fit(data)  # 训练模型\n",
    "c = pd.DataFrame(kmodel.cluster_centers_, columns=['cc']) # 求聚类中心\n",
    "c0 = pd.DataFrame({'cc': [0.0]})\n",
    "c = pd.concat([c0, c], axis=0, ignore_index=True)\n",
    "c = c.sort_values(by='cc').reset_index(drop=True)\n",
    "\n",
    "# 求聚类中心之间的平均值作为分割点\n",
    "for i in range(c.shape[0] - 1):\n",
    "    c.iloc[i]['cc'] = (c.iloc[i]['cc'] + c.iloc[i+1]['cc']) / 2\n",
    "c = c.drop(c.index[-1])\n",
    "\n",
    "c0 = pd.DataFrame({'cc': [0.0]})\n",
    "cn = pd.DataFrame({'cc': [max(train['BN'].max(), test['BN'].max()) * 5]})\n",
    "c = pd.concat([c0, c, cn], axis=0, ignore_index=True)\n",
    "c = c['cc'].round().astype(int)\n",
    "c = c.unique()\n",
    "range_num = c.shape[0] - 1\n",
    "c = c.tolist()\n",
    "\n",
    "# 保留旧BN，添加BN_binning\n",
    "train_BN = train['BN'].values\n",
    "train_binning = pd.cut(train_BN, c, labels=range(range_num), include_lowest=True)\n",
    "train['BN_binning'] = train_binning\n",
    "\n",
    "test_BN = test['BN'].values\n",
    "test_binning = pd.cut(test_BN, c, labels=range(range_num), include_lowest=True)\n",
    "test['BN_binning'] = test_binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_meta = greeks['Alpha'].values\n",
    "X = train.drop(columns=['Id', 'Class'])\n",
    "y = train['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['AB', 'AF', 'AM', 'AX', 'AZ', 'BC', 'BD ', 'BN', 'BP', 'BQ', 'BR', 'CB',\n",
      "       'CC', 'CD ', 'CF', 'CH', 'CR', 'CS', 'CU', 'DA', 'DE', 'DF', 'DH', 'DI',\n",
      "       'DL', 'DN', 'DU', 'DY', 'EB', 'EE', 'EG', 'EH', 'EL', 'EP', 'FC', 'FD ',\n",
      "       'FE', 'FI', 'FL', 'FR', 'GB', 'GE', 'GF', 'GH', 'GL'],\n",
      "      dtype='object')\n",
      "{'EU', 'EJ', 'AY', 'BZ', 'AH', 'FS', 'CW ', 'GI', 'CL', 'BN_binning', 'AR', 'DV'}\n"
     ]
    }
   ],
   "source": [
    "# RFE寻找可以删除的特征\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X = train.drop(columns=['Id', 'Class'])\n",
    "y = train['Class']\n",
    "\n",
    "model = RandomForestClassifier(random_state=1)\n",
    "rfe = RFE(model, n_features_to_select=45)\n",
    "rfe = rfe.fit(X, y)\n",
    "\n",
    "features_selected = X.columns[rfe.support_]\n",
    "all_features = X.columns\n",
    "\n",
    "not_selected_features = set(all_features) - set(features_selected)\n",
    "\n",
    "print(features_selected)\n",
    "print(not_selected_features)\n",
    "\n",
    "X_new = rfe.transform(X)\n",
    "test_new = rfe.transform(test.drop(columns=['Id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Feature 1 Feature 2      关系类型\n",
      "0        AF        DU  非线性/交互关系\n",
      "1        DI        DU  非线性/交互关系\n"
     ]
    }
   ],
   "source": [
    "# 通过线性回归找到可以进行多项式组合的特征\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "train = train.drop(['Id'],axis=1)\n",
    "\n",
    "# 列名列表，所有特征列\n",
    "all_features = train.columns\n",
    "\n",
    "# 用于存储特征之间是否存在非线性关系或交互关系的结果\n",
    "result = []\n",
    "\n",
    "# 遍历每两个特征的组合\n",
    "for feature_pair in itertools.combinations(all_features, 2):\n",
    "    feature_1, feature_2 = feature_pair\n",
    "    \n",
    "    # 创建包含两个特征的DataFrame\n",
    "    features_df = train[[feature_1, feature_2]]\n",
    "    \n",
    "    # 使用多项式特征衍生\n",
    "    poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    poly_features = poly.fit_transform(features_df)\n",
    "    \n",
    "    # 拟合线性回归模型\n",
    "    model = LinearRegression()\n",
    "    model.fit(poly_features, train['Class'])  # 将目标变量替换为你的目标变量列名\n",
    "    \n",
    "    # 检查模型的性能或某些条件，判断是否存在非线性关系或交互关系\n",
    "    # 这里仅仅是一个示例，你可以根据你的具体需求进行判断\n",
    "    if model.score(poly_features, train['Class']) > 0.26 and feature_1 != 'Class' and feature_2 != 'Class':\n",
    "        result.append((feature_1, feature_2, '非线性/交互关系'))\n",
    "    # else:\n",
    "    #     result.append((feature_1, feature_2, '无关系'))\n",
    "\n",
    "# 将结果转换为 DataFrame\n",
    "result_df = pd.DataFrame(result, columns=['Feature 1', 'Feature 2', '关系类型'])\n",
    "\n",
    "# 打印结果\n",
    "print(result_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
